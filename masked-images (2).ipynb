{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This cell is for installing the COCO API, which helps read the annotation files.\n# It's typically pre-installed on Kaggle, but this ensures it's available.\n!pip install pycocotools --quiet\n\nimport os\nimport json\nimport random\nimport numpy as np\nfrom pycocotools.coco import COCO\nfrom PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\n\nprint(\"Libraries imported successfully.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the paths to the dataset\n# This path is standard for this dataset on Kaggle\nBASE_PATH = '/kaggle/input/coco-2017-dataset/coco2017/'\nIMG_PATH = os.path.join(BASE_PATH, 'train2017')\nANN_PATH = os.path.join(BASE_PATH, 'annotations', 'instances_train2017.json')\n\n# Initialize the COCO API for instance annotations\nprint(\"Loading annotations... This may take a moment.\")\ncoco = COCO(ANN_PATH)\nprint(\"Annotations loaded.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get all image IDs from the training set\nall_img_ids = coco.getImgIds()\nprint(f\"Total images in the training set: {len(all_img_ids)}\")\n\n# Collect the first 20,000 image IDs\nimage_ids_20k = all_img_ids[:20000]\n\nprint(f\"Collected {len(image_ids_20k)} image IDs to work with.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select 50 images from our 20k list for visualization\n# We'll take the first 50\nimages_to_visualize = image_ids_20k[:50]\n\nprint(f\"Starting visualization for {len(images_to_visualize)} images...\")\n\nfor img_id in images_to_visualize:\n    # 1. Load Image Info\n    img_info = coco.loadImgs([img_id])[0]\n    img_path = os.path.join(IMG_PATH, img_info['file_name'])\n    \n    # 2. Load Original Image (as RGB)\n    original_image = Image.open(img_path).convert('RGB')\n    \n    # 3. Get all annotations for this image\n    ann_ids = coco.getAnnIds(imgIds=img_id)\n    annotations = coco.loadAnns(ann_ids)\n    \n    # 4. Create the segmentation mask using numpy and coco.annToMask\n    # This is more robust as it handles both polygon and RLE formats.\n    \n    # Create a blank numpy array for the combined mask\n    combined_mask_np = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n    \n    # Iterate over all annotations (all subjects) for this image\n    for ann in annotations:\n        # coco.annToMask returns a binary 0/1 numpy array\n        # This function correctly handles both RLE and polygon formats\n        single_ann_mask_np = coco.annToMask(ann)\n        \n        # Combine masks using logical OR\n        # This adds the current object's mask to the combined mask\n        combined_mask_np = np.logical_or(combined_mask_np, single_ann_mask_np).astype(np.uint8)\n\n    # Convert the final combined numpy mask (0/1) to a PIL Image (0/255)\n    # We multiply by 255 to make the mask visible (white) for PIL\n    mask_pil = Image.fromarray(combined_mask_np * 255, 'L')\n    \n    # 5. Create the final \"Subject Isolated\" image\n    # This creates a black RGB background\n    black_bg = Image.new('RGB', original_image.size, (0, 0, 0))\n    \n    # Use the PIL mask to composite the images\n    # Where mask_pil is 255 (white), pixels from original_image are used.\n    # Where mask_pil is 0 (black), pixels from black_bg are used.\n    masked_image = Image.composite(original_image, black_bg, mask_pil)\n    \n    # 6. Visualize side-by-side\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n    \n    # Original Image\n    ax1.imshow(original_image)\n    ax1.set_title(f\"Original Image: {img_info['file_name']}\")\n    ax1.axis('off')\n    \n    # Masked Image (Subject Isolated)\n    ax2.imshow(masked_image)\n    ax2.set_title(\"Masked Image (Subject Isolated)\")\n    ax2.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nprint(\"Visualization complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}