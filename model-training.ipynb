{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":13779028,"sourceType":"datasetVersion","datasetId":8770479}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport time\n\na = tf.random.normal((3000, 3000))\nb = tf.random.normal((3000, 3000))\n\nstart = time.time()\nc = tf.matmul(a, b)\ntf.print(\"Time:\", time.time() - start)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n#   SINGLE-CELL: High Accuracy + Fast Training + Local ResNet50\n# ============================================================\n\n# ---------------- USER SETTINGS ----------------\nENCODER = \"resnet50\"        # Best accuracy\nUSE_LOCAL_RESNET = True\nLOCAL_RESNET_DIR = \"/kaggle/input/resnet50-pretrained-weights\"\nLOCAL_RESNET_WEIGHTS = LOCAL_RESNET_DIR + \"/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n\nCOCO_DIR = \"/kaggle/input/coco-2017-dataset\"\nMAX_IMAGES = 40000\nIMG_SIZE = (256, 256)\nBATCH = 8\nEPOCHS = 8\nSEED = 42\n\nAUTO_WRITE_TFRECORD = True\nTRAIN_NOW = True\n# ------------------------------------------------\n\n# ================= ENVIRONMENT SAFE =================\nimport os\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=false\"\n\n# ================= IMPORTS =================\nimport gc, math, time\nfrom pathlib import Path\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nprint(\"TensorFlow:\", tf.__version__)\n\ngpus = tf.config.list_physical_devices(\"GPU\")\nprint(\"GPUs detected:\", gpus)\n# ❌ DO NOT set memory growth — Kaggle initializes TF early\n\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\nprint(\"Mixed precision ON\")\n\n# ================= PATHS =================\nBASE_INPUT = Path(COCO_DIR) / \"coco2017\"\nIMG_DIR = BASE_INPUT / \"train2017\"\nANN_PATH = BASE_INPUT / \"annotations\" / \"instances_train2017.json\"\n\nOUT = Path(\"/kaggle/working/coco_processed\")\nRGB_DIR = OUT / \"rgb_256\"\nGRAY_DIR = OUT / \"gray_256\"\nMASK_DIR = OUT / \"masks_256\"\nTF_DIR = Path(\"/kaggle/working/tfrecords\")\n\nTF_DIR.mkdir(parents=True, exist_ok=True)\nfor d in [OUT, RGB_DIR, GRAY_DIR, MASK_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\nTRAIN_TF = TF_DIR / \"train.tfrecord\"\nVAL_TF   = TF_DIR / \"val.tfrecord\"\n\nprint(\"COCO found:\", IMG_DIR.exists(), ANN_PATH.exists())\nprint(\"Local ResNet weights found:\", Path(LOCAL_RESNET_WEIGHTS).exists())\n\n# ================= LOAD COCO =================\nfrom pycocotools.coco import COCO\ncoco = COCO(str(ANN_PATH))\nall_ids = coco.getImgIds()\nimage_ids = all_ids[:MAX_IMAGES]\nprint(\"Images used:\", len(image_ids))\n\nIMG_H, IMG_W = IMG_SIZE\n\n# ================= STEP 1: MASKED RGB =================\nif len(list(RGB_DIR.glob(\"*.jpg\"))) < len(image_ids):\n    print(\"Creating masked RGB images...\")\n    for iid in tqdm(image_ids):\n        out = RGB_DIR / f\"{iid}.jpg\"\n        if out.exists():\n            continue\n        info = coco.loadImgs([iid])[0]\n        img = cv2.imread(str(IMG_DIR / info[\"file_name\"]))\n        if img is None: \n            continue\n\n        h, w = img.shape[:2]\n        ann_ids = coco.getAnnIds(imgIds=iid)\n        mask = np.zeros((h, w), dtype=np.uint8)\n        for ann in coco.loadAnns(ann_ids):\n            mask = np.logical_or(mask, coco.annToMask(ann)).astype(np.uint8)\n\n        masked = img * mask[..., None]\n        masked = cv2.resize(masked, IMG_SIZE)\n        cv2.imwrite(str(out), masked)\nelse:\n    print(\"RGB_DIR already complete. Skipping.\")\n\n# ================= STEP 2: GRAYSCALE =================\nif len(list(GRAY_DIR.glob(\"*.jpg\"))) < len(image_ids):\n    print(\"Converting to grayscale...\")\n    for p in tqdm(sorted(RGB_DIR.glob(\"*.jpg\"))):\n        out = GRAY_DIR / p.name\n        if out.exists(): \n            continue\n        img = cv2.imread(str(p))\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        gray = cv2.resize(gray, IMG_SIZE)\n        cv2.imwrite(str(out), gray)\nelse:\n    print(\"GRAY_DIR already complete. Skipping.\")\n\n# ================= STEP 3: MASKS =================\nif len(list(MASK_DIR.glob(\"*.npy\"))) < len(image_ids):\n    print(\"Creating masks...\")\n    for iid in tqdm(image_ids):\n        out = MASK_DIR / f\"{iid}.npy\"\n        if out.exists():\n            continue\n\n        info = coco.loadImgs([iid])[0]\n        h, w = info[\"height\"], info[\"width\"]\n\n        ann_ids = coco.getAnnIds(imgIds=iid)\n        mask = np.zeros((h, w), dtype=np.uint8)\n        for ann in coco.loadAnns(ann_ids):\n            mask = np.logical_or(mask, coco.annToMask(ann)).astype(np.uint8)\n\n        mask = cv2.resize(mask, IMG_SIZE, interpolation=cv2.INTER_NEAREST)\n        np.save(str(out), mask.astype(\"uint8\"))\nelse:\n    print(\"MASK_DIR already complete. Skipping.\")\n\n# ================= STEP 4: PAIRS =================\npairs = []\nfor p in sorted(GRAY_DIR.glob(\"*.jpg\")):\n    iid = p.stem\n    mask = MASK_DIR / f\"{iid}.npy\"\n    if mask.exists():\n        pairs.append((str(p), str(mask)))\n\nprint(\"Total pairs:\", len(pairs))\n\nfrom sklearn.model_selection import train_test_split\ntrain_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=SEED)\n\n# ================= STEP 5: TFRecords =================\ndef write_tfrecord(pairs_list, out_path):\n    with tf.io.TFRecordWriter(str(out_path)) as w:\n        for img_path, mask_path in tqdm(pairs_list):\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, IMG_SIZE)\n            img = np.repeat(img[..., None], 3, axis=-1).astype(np.uint8)\n\n            mask = np.load(mask_path).astype(np.uint8)\n            mask = cv2.resize(mask, IMG_SIZE)\n            mask = mask[..., None].astype(np.uint8)\n\n            example = tf.train.Example(features=tf.train.Features(feature={\n                \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[img.tobytes()])),\n                \"mask\":  tf.train.Feature(bytes_list=tf.train.BytesList(value=[mask.tobytes()])),\n            }))\n            w.write(example.SerializeToString())\n\nif AUTO_WRITE_TFRECORD:\n    if not TRAIN_TF.exists():\n        write_tfrecord(train_pairs, TRAIN_TF)\n    else:\n        print(\"Train TFRecord exists.\")\n    if not VAL_TF.exists():\n        write_tfrecord(val_pairs, VAL_TF)\n    else:\n        print(\"Val TFRecord exists.\")\n\n# ================= STEP 6: tf.data =================\nAUTOTUNE = tf.data.AUTOTUNE\n\ndef parse(ex):\n    feat = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"mask\":  tf.io.FixedLenFeature([], tf.string),\n    }\n    parsed = tf.io.parse_single_example(ex, feat)\n    img = tf.io.decode_raw(parsed[\"image\"], tf.uint8)\n    img = tf.reshape(img, [IMG_H, IMG_W, 3])\n    img = tf.cast(img, tf.float32) / 255.0\n\n    mask = tf.io.decode_raw(parsed[\"mask\"], tf.uint8)\n    mask = tf.reshape(mask, [IMG_H, IMG_W, 1])\n    mask = tf.cast(mask, tf.float32)\n    return img, mask\n\ndef make_ds(path, train=True):\n    ds = tf.data.TFRecordDataset(str(path), num_parallel_reads=AUTOTUNE)\n    ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n    if train:\n        ds = ds.shuffle(4096)\n    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n    return ds\n\ntrain_ds = make_ds(TRAIN_TF, True)\nval_ds   = make_ds(VAL_TF, False)\n\nprint(\"Dataset ready.\")\n\n# ================= STEP 7: MODEL =================\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.applications import ResNet50\n\ndef build_unet_resnet50():\n    base = ResNet50(weights=None, include_top=False, input_shape=(IMG_H, IMG_W, 3))\n    base.load_weights(LOCAL_RESNET_WEIGHTS)\n    print(\"Loaded LOCAL ResNet50 weights.\")\n\n    c1 = base.get_layer(\"conv1_relu\").output\n    c2 = base.get_layer(\"conv2_block3_out\").output\n    c3 = base.get_layer(\"conv3_block4_out\").output\n    c4 = base.get_layer(\"conv4_block6_out\").output\n    bn = base.get_layer(\"conv5_block3_out\").output\n\n    def up(x, skip, f):\n        x = layers.Conv2DTranspose(f, 2, strides=2, padding=\"same\")(x)\n        x = layers.Concatenate()([x, skip])\n        x = layers.Conv2D(f, 3, activation=\"relu\", padding=\"same\")(x)\n        x = layers.Conv2D(f, 3, activation=\"relu\", padding=\"same\")(x)\n        return x\n\n    u1 = up(bn, c4, 256)\n    u2 = up(u1, c3, 128)\n    u3 = up(u2, c2, 64)\n    u4 = up(u3, c1, 32)\n\n    u5 = layers.Conv2DTranspose(16, 2, strides=2, padding=\"same\")(u4)\n    u5 = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(u5)\n\n    out = layers.Conv2D(1, 1, activation=\"sigmoid\", dtype=\"float32\")(u5)\n    return Model(base.input, out)\n\nmodel = build_unet_resnet50()\nmodel.summary()\n\n# ================= STEP 8: LOSS & COMPILE =================\ndef dice_loss(y_true, y_pred, smooth=1e-6):\n    inter = tf.reduce_sum(y_true * y_pred)\n    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n    return 1 - (2*inter+smooth)/(denom+smooth)\n\nloss_fn = lambda y_true, y_pred: (\n    tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=loss_fn,\n    metrics=[\"accuracy\"]\n)\n\n# ================= STEP 9: TRAIN =================\nif TRAIN_NOW:\n    print(\"Training...\")\n    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n    model.save(\"/kaggle/working/unet_final.h5\", include_optimizer=False)\n\n    print(\"Model saved at /kaggle/working/unet_final.h5\")\nelse:\n    print(\"TRAIN_NOW=False — finished preprocessing.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a clean model copy without optimizer/loss/lambda\nclean_model = tf.keras.models.Model(\n    inputs=model.input,\n    outputs=model.output\n)\n\nclean_model.save(\"/kaggle/working/unet_final_clean.keras\", include_optimizer=False)\nprint(\"Saved clean model at /kaggle/working/unet_final_clean.keras\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"/kaggle/working/unet_final_clean.keras\", compile=False)\nprint(\"Loaded clean model\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport random\nimport tensorflow as tf\n\n# ================= LOAD CLEAN MODEL =================\nmodel_path = \"/kaggle/working/unet_final_clean.keras\"\nprint(\"Loading model from:\", model_path)\n\nmodel = tf.keras.models.load_model(model_path, compile=False)\nprint(\"Model loaded successfully!\")\n\n# ================= IMAGE LOADER =================\ndef load_gray_image(path):\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (256,256))\n    img = np.repeat(img[..., None], 3, axis=-1)   # convert gray → 3 channels\n    img = img.astype(np.float32) / 255.0\n    return img\n\n# ================= VISUALIZATION =================\nnum_tests = 5\nplt.figure(figsize=(15, num_tests * 4))\n\nfor i in range(num_tests):\n    img_path, mask_path = random.choice(val_pairs)\n\n    # Load image\n    img = load_gray_image(img_path)\n\n    # Load mask\n    mask = np.load(mask_path)\n    mask = cv2.resize(mask, (256, 256))\n\n    # Predict\n    pred = model.predict(img[None, ...])[0]\n    pred_bin = (pred > 0.5).astype(\"uint8\")\n\n    # ==== DISPLAY ====\n    plt.subplot(num_tests, 3, i*3+1)\n    plt.imshow(img[...,0], cmap=\"gray\")\n    plt.title(\"Input Image\")\n    plt.axis(\"off\")\n\n    plt.subplot(num_tests, 3, i*3+2)\n    plt.imshow(mask, cmap=\"gray\")\n    plt.title(\"Ground Truth Mask\")\n    plt.axis(\"off\")\n\n    plt.subplot(num_tests, 3, i*3+3)\n    plt.imshow(pred_bin[:,:,0], cmap=\"gray\")\n    plt.title(\"Predicted Mask\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}